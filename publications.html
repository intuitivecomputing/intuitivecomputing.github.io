a<!DOCTYPE HTML>
<!--
	Spectral by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
  <title>Publications | Intuitive Computing Laboratory</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <link rel="stylesheet" href="assets/css/main.css" />
  <link rel="stylesheet" href="assets/css/icl.css" /> <!-- lab custom css -->
  <noscript>
    <link rel="stylesheet" href="assets/css/noscript.css" /></noscript>

</head>

<body class="is-preload">

  <!-- Page Wrapper -->
  <div id="page-wrapper">

    <!-- Header -->
    <header id="header">
      <h1><a href="index.html">Intuitive Computing Laboratory</a></h1>
      <nav id="nav">
        <ul>
          <li class="special">
            <a href="#menu" class="menuToggle"><span>Menu</span></a>
            <div id="menu">
              <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="news.html">News</a></li>
                <li><a href="team.html">Team</a></li>
                <li><a href="research.html">Research</a></li>
                <li><a href="openscience.html">Open Science</a></li>
                <li><a href="publications.html">Publications</a></li>
                <li><a href="join.html">Join Us</a></li>
              </ul>
            </div>
          </li>
        </ul>
      </nav>
    </header>

    <!-- Main -->
    <article id="publications_main" class="alt">
      <header>
        <h2>Publications</h2>
        <p></p>
      </header>
      <section class="wrapper style5">
        <div class="inner">

          <h3>2021</h3>
          <p>Gopika Ajaykumar, Maia Stiber, and Chien-Ming Huang<br>
          <span class="pub_hl">Designing User-Centric Programming Aids for Kinesthetic Teaching of Collaborative Robots</span> <br>
          <b>Journal</b>: Robotics and Autonomous Systems<br>
          [<a href="publications/2021-ras-ajaykumar.pdf" id="pub">paper</a>] | [<a href="https://github.com/intuitivecomputing/demoshop" id="pub">software</a>] | [<a href="https://www.youtube.com/watch?v=qvTMBZkvxwM" id="pub">video</a>]</p>

          <p>Yuxiang Gao, Kapil Katyal, Jared Markowitz, I-Jeng Wang, and Chien-Ming Huang<br>
          <span class="pub_hl">Don't be Rude! Learning Group-aware Policies for Robot Navigation</span> <br>
          <b>Workshop</b>: 2021 RSS Workshop on Social Robot Navigation<br>
          [<a href="publications/2021-rssws-gao.pdf" id="pub">paper</a>]</p>

          <p>Gopika Ajaykumar and Chien-Ming Huang<br>
          <span class="pub_hl">Multimodal Robot Programming by Demonstration: A Preliminary Exploration</span> <br>
          <b>Workshop</b>: 2021 RSS Workshop on Accessibility of Robot Programming and the Work of the Future<br>
          [<a href="publications/2021-rssws-ajaykumar.pdf" id="pub">paper</a>]</p>

          <p>Gopika Ajaykumar, Annie Mao, Jeremy Brown, and Chien-Ming Huang<br>
          <span class="pub_hl">FACT: A Full-body Ad-hoc Collaboration Testbed for Modeling Complex Teamwork</span> <br>
          <b>Workshop</b>: 2021 ICRA Workshop on Social Intelligence in Humans and Robots<br>
          [<a href="https://arxiv.org/pdf/2106.03290.pdf" id="pub">paper</a>]</p>

          <p>Gopika Ajaykumar, Maureen Steele, and Chien-Ming Huang<br>
          <span class="pub_hl">A Survey on End-User Robot Programming</span> <br>
          <b>Journal</b>: ACM Transactions on Computing Survey<br>
          [paper]</p>

          <p>Julia Oppenhein, Jindan Huang, Isabel Won, and Chien-Ming Huang.<br>
          <span class="pub_hl">Mental Synchronization in Human Task Demonstration: Implications for Robot Teaching and Learning</span> <br>
          <b>Conference LBR</b>: ACM/IEEE International Conference on Human-Robot Interaction Late-Breaking Report (HRI’21 LBR)<br>
          [<a href="publications/2021-hri-oppenheim.pdf" id="pub">paper</a>] | <pub_note>*equal contribution</pub_note></p>

          <h3>2020</h3>
          <p>Fanjun Bu and Chien-Ming Huang<br>
          <span class="pub_hl">Dataset: Audio-Visual Representations of Object Drops</span> <br>
          Johns Hopkins University Data Archive, V1<br>
          [<a href="https://doi.org/10.7281/T1/EP0W7Y" id="pub">dataset</a>]</p>

          <p>Maia Stiber and Chien-Ming Huang<br>
          <span class="pub_hl">Not All Errors Are Created Equal: Exploring Human Responses to Robot Errors with Varying Severity</span> <br>
          <b>Conference LBR</b>: ACM International Conference on Multimodal Interaction Late-Breaking Report (ICMI’20 LBR)<br>
          [<a href="publications/2020-icmi-stiber.pdf" id="pub">paper</a>] | [<a href="https://www.youtube.com/watch?v=fNO67cWELp0" id="pub">talk</a>]</p>

          <p>Ji Han*, Gopika Ajaykumar*, Ze Li, and Chien-Ming Huang<br>
          <span class="pub_hl">Structuring Human-Robot Interactions via Interaction Conventions</span><br>
          <b>Conference</b>: IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN’20)<br>
          [<a href="publications/2020-roman-han.pdf" id="pub">paper </a>] | [<a href="https://www.youtube.com/watch?v=L1cXn9HWUxg" id="pub">talk</a>] | <pub_note>*equal contribution</pub_note></p>

          <p>Ehsan Azimi, Zhiyuan Niu, Maia Stiber, Nicholas Greene, Ruby Liu, Camilo Molina, Judy Huang, Chien-Ming Huang, and Peter Kazanzides<br>
          <span class="pub_hl">An Interactive Mixed Reality Platform for Bedside Surgical Procedures</span><br>
          <b>Conference</b>: International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI’20)<br>
          [<a href="publications/2020-miccai-azimi.pdf" id="pub">paper</a>] </p>

          <p>Amama Mahmood<br>
          <span class="pub_hl">Robot Assisted 3D Block Building to Augment Spatial Visualization Skills in Children – An Exploratory Study</span><br>
          Master of Science in Engineering in Robotics (Robotics MSE) Essay. Johns Hopkins University<br> 
          [<a href="publications/2020-robotics-mse-Mahmood.pdf" id="pub">paper</a>] </p>

          <p>Chien-Ming Huang<br>
          <span class="pub_hl">Contextual Programming of Collaborative Robots</span><br>
          <b>Conference</b>: International Conference on Human-Computer Interaction (HCII’20)<br>
          [<a href="publications/2020-hcii-huang.pdf" id="pub">paper</a>] | <pub_note>invited paper</pub_note> </p>

          <p>Kapil Katyal, Gregory Hager, and Chien-Ming Huang<br>
          <span class="pub_hl">Intent-Aware Pedestrian Prediction for Adaptive Crowd Navigation</span><br>
          <b>Conference</b>: IEEE International Conference on Robotics and Automation (ICRA’20)<br>
          [<a href="publications/2020-icra-katyal.pdf" id="pub">paper</a>] | <pub_note>acceptance rate: 42%</pub_note></p>

          <p>Gopika Ajaykumar and Chien-Ming Huang<br>
          <span class="pub_hl">User Needs and Design Opportunities in End-User Robot Programming</span><br>
          <b>Conference LBR</b>: ACM/IEEE International Conference on Human-Robot Interaction Late-Breaking Report (HRI’20 LBR)<br>
          [<a href="publications/2020-hri-ajaykumar.pdf" id="pub">paper</a>] | [<a href="https://www.youtube.com/watch?v=nlRoyGLH5ok" id="pub">talk</a>]</p>

          <p>Yeping Wang, Gopika Ajaykumar, and Chien-Ming Huang<br>
          <span class="pub_hl">See What I See: Enabling User-Centric Robotic Assistance Using First-Person Demonstrations</span><br>
          <b>Conference</b>: ACM/IEEE International Conference on Human-Robot Interaction (HRI’20)<br>
          [<a href="publications/2020-hri-wang.pdf" id="pub">paper</a>] | [<a href="https://www.youtube.com/watch?v=IOwl3GTZI7k" id="pub">talk</a>] | <pub_note>acceptance rate: 24%</pub_note> </p>

          <h3>2019</h3>
          <p>Kapil Katyal, I-Jeng Wang, Gregory Hager, and Chien-Ming Huang<br>
          <span class="pub_hl">Intent-Aware Human Motion Prediction using Deep Generative Neural Networks</span><br>
          <b>Workshop</b>: Do Good Robotics Symposium<br>
          [<a href="publications/2019-dgrs-katyal.pdf" id="pub">paper</a>] </p>

          <p>Barton Paulhamus, Edward Staley, Corban Rivera, Kapil Katyal, and Chien-Ming Huang<br>
          <span class="pub_hl">Amplified Control for Robotic Teleoperation</span><br>
          <b>Workshop</b>: Do Good Robotics Symposium<br>
          [<a href="publications/2019-dgrs-paulhamus.pdf" id="pub">paper</a>] </p>

          <p>Yuxiang Gao and Chien-Ming Huang<br>
          <span class="pub_hl">Robot Programming by Situated Illustration</span><br>
          <b>Workshop</b>: Do Good Robotics Symposium<br>
          [<a href="publications/2019-dgrs-gao.pdf" id="pub">paper</a>] </p>

          <p>Amrita Krishnaraj<br>
          <span class="pub_hl">Designing Social Robots for Early Detection of Mental Heath Conditions</span><br> Master of Science in Engineering in Robotics (Robotics MSE) Essay. Johns Hopkins University<br> 
          [<a href="publications/2019-robotics-mse-Krishnaraj.pdf" id="pub">paper</a>] </p>

          <p>Aditi Ramachandran, Chien-Ming Huang, and Brian Scassellati<br> 
          <span class="pub_hl">Toward Effective Robot-Child Tutoring: Intrinsic Motivation, Behavioral Intervention, and Learning Outcomes</span><br>
          <b>Journal</b>: ACM Transactions on Interactive Intelligent Systems<br>
          [<a href="https://dl.acm.org/citation.cfm?id=3213768" id="pub">paper</a>] </p>

          <p>Yuxiang Gao and Chien-Ming Huang<br>
          <span class="pub_hl">PATI: A Projection-based Augmented Table-Top Interface for Robot Programming</span><br>
          <b>Conference</b>: ACM International Conference on Intelligent User Interface (IUI’19)<br> 
          [<a href="publications/2019-iui-gao.pdf" id="pub">paper</a>] | [<a href="https://sites.google.com/view/icl-pati" id="pub">project page</a>] | [<a href="https://www.youtube.com/watch?v=NqozqXzkFek" id="pub">talk</a>] | <pub_note>acceptance rate: 25%</pub_note></p>

          <h3>2018</h3>
          <p>Brain Scassellati, Laura Boccanfuso*, Chien-Ming Huang*, Marilena Mademtzi*, Meiying Qin*, Nicole Salomons*, Pamela Ventola, and Frederick Shic<br>
          <span class="pub_hl">Improving Social Skills in Children with ASD Using a Long-Term, In-Home Social Robot</span><br>
          <b>Journal</b>: Science Robotics<br>
          [<a href="https://robotics.sciencemag.org/content/robotics/3/21/eaat7544.full.pdf?casa_token=vh-Sc7qHGHsAAAAA:Ash9VEBe8kcwDX1nQL8onkQYiHVsk_AaBHQ2DL_JjEOWmnLomrmGDkN9igsdDN6p8iDU-ToiULvZ" id="pub">paper</a>] | <pub_note>*equal contribution</pub_note> </p> 

          <p>Ehsan Azimi, Camilo Molina, Alexander Chang, Judy Huang, Chien-Ming Huang, and Peter Kazanzides<br>
          <span class="pub_hl">Interactive Training and Operation Ecosystem for Surgical Tasks in Mixed Reality</span><br>
          <b>Workshop</b>: OR 2.0 Context-Aware Surgical Theaters (MICCAI’18)<br>
          [<a href="https://or20.univ-rennes1.fr/sites/or20.univ-rennes1.fr/files/asset/document/interactive-training-camera-ready.pdf" id="pub">paper</a>] </p>

          <p>Aditi Ramachandran, Chien-Ming Huang, Edward Gartland, and Brian Scassellati<br>
          <span class="pub_hl">Thinking Aloud with a Tutoring Robot to Enhance Learning</span><br>
          <b>Conference</b>: ACM/IEEE International Conference on Human-Robot Interaction (HRI’18)<br>
          [<a href="https://dl.acm.org/citation.cfm?id=3171250" id="pub">paper</a>] | <pub_note>acceptance rate: 23%</pub_note></p>

          <h3>2017</h3>
          <p>Aditi Ramachandran, Chien-Ming Huang, and Brian Scassellati<br>
          <span class="pub_hl">Give Me a Break! Personalized Timing Strategies to Promote Learning in Robot-Child Tutoring</span><br>
          <b>Conference</b>: ACM/IEEE International Conference on Human-Robot Interaction (HRI’17)<br>
          [<a href="publications/2017-hri-ramachandran.pdf" id="pub">paper</a>] | <pub_note>acceptance rate: 24%</pub_note></p>

          <h3>2016</h3>
          <p>Sarah Strohkorb, Chien-Ming Huang, Aditi Ramachandran, and Brian Scassellati<br>
          <span class="pub_hl">Establishing Sustained, Supportive Human-Robot Relationships: Building Blocks and Open Challenges</span><br>
          AAAI Spring Symposium<br>
          [<a href="http://www.aaai.org/ocs/index.php/SSS/SSS16/paper/download/12702/11942" id="pub">paper</a>] </p>

          <p>Chien-Ming Huang and Bilge Mutlu<br>
          <span class="pub_hl">Anticipatory Robot Control for Efficient Human-Robot Collaboration</span><br>
          <b>Conference</b>: ACM/IEEE International Conference on Human-Robot Interaction (HRI’16)<br>
          [<a href="publications/2016-hri-huang.pdf" id="pub">paper</a>] | <pub_note>acceptance rate: 25%</pub_note></p>

          <h3>2015</h3>
          <p>Chien-Ming Huang<br>
          <span class="pub_hl">Human-Robot Joint Action: Coordinating Attention, Communication, and Actions</span><br>
      	  Doctor of Philosophy (Ph.D.) Thesis. Department of Computer Sciences, University of Wisconsin–Madison</p>

          <p>Chien-Ming Huang, Sean Andrist, Allison Sauppé, and Bilge Mutlu<br>
          <span class="pub_hl">Using Gaze Patterns to Predict Task Intent in Collaboration</span><br>
          <b>Journal</b>: Frontiers in Psychology -- Cognitive Science<br>
          [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4513212/" id="pub">paper</a>] </p>

          <p>Chien-Ming Huang, Maya Cakmak, and Bilge Mutlu<br>
          <span class="pub_hl">Adaptive Coordination Strategies for Human-Robot Handovers</span><br>
          <b>Conference</b>: Robotics: Science and Systems Conference (RSS’15)<br>
          [<a href="http://roboticsproceedings.org/rss11/p31.pdf" id="pub">paper</a>] | <pub_note>acceptance rate: 26%</pub_note></p>

          <p>Allison Sauppé and Chien-Ming Huang<br>
          <span class="pub_hl">Teaching Human-Robot Interaction Using the CSTA Recommendations</span><br>
          <b>Workshop</b>: HRI Education Workshop: How to design and teach courses in Human-Robot Interaction (HRI’15)</p>

          <p>Allison Sauppé, Daniel Szafir, Chien-Ming Huang, and Bilge Mutlu<br>
          <span class="pub_hl">From 9 to 90: Engaging Learners of All Ages</span><br>
          <b>Conference</b>: ACM Technical Symposium on Computer Science Education (SIGCSE'15)<br>
          [<a href="https://dl.acm.org/authorize.cfm?key=N42660" id="pub">paper</a>] | <pub_note>acceptance rate: 36%</pub_note></p>

          <h3>2014</h3>
          <p>Chien-Ming Huang and Bilge Mutlu<br>
          <span class="pub_hl">Multivariate Evaluation of Interactive Robot Systems</span><br>
          <b>Journal</b>: Autonomous Robots<br>
          [<a href="https://link.springer.com/article/10.1007/s10514-014-9415-y" id="pub">paper</a>] </p>

          <p>Chien-Ming Huang, Takamasa Iio, Satoru Satake, and Takayuki Kanda<br>
          <span class="pub_hl">Modeling and Controlling Friendliness for an Interactive Museum Robot</span><br>
          <b>Conference</b>: Robotics: Science and Systems Conference (RSS’14)<br>
          [<a href="http://roboticsproceedings.org/rss10/p25.pdf" id="pub">paper</a>] | <pub_note>acceptance rate: 32%</pub_note></p>

          <p>Chien-Ming Huang and Bilge Mutlu<br>
          <span class="pub_hl">Learning-based Modeling of Multimodal Behaviors for Humanlike Robots</span><br>
          <b>Conference</b>: ACM/IEEE International Conference on Human-Robot Interaction (HRI’14)<br>
          [<a href="https://dl.acm.org/authorize.cfm?key=N71261" id="pub">paper</a>] | <pub_note>acceptance rate: 24%</pub_note></p>

          <p>Chien-Ming Huang and Bilge Mutlu<br>
          <span class="pub_hl">Modeling Human-Robot Interactions as Systems of Distributed Cognition</span><br>
          AAAI Fall Symposium on Artificial Intelligence and Human-Robot Interaction (AI-HRI)<br>
          [<a href="https://www.aaai.org/ocs/index.php/FSS/FSS14/paper/viewFile/9209/9154" id="pub">paper</a>] </p>

          <h3>2013</h3>
          <p>Chien-Ming Huang and Bilge Mutlu<br>
          <span class="pub_hl">The Repertoire of Robot Behavior: Enabling Robots to Achieve Interaction Goals through Social Behavior</span><br>
          <b>Journal</b>: Journal of Human-Robot Interaction (ACM Transactions on Human-Robot Interaction)<br>
          [<a href="http://humanrobotinteraction.org/journal/index.php/HRI/article/view/122/101" id="pub">paper</a>] </p>

          <p>Chien-Ming Huang and Bilge Mutlu<br>
          <span class="pub_hl">Modeling and Evaluating Narrative Gestures for Humanlike Robots</span><br>
          <b>Conference</b>: Robotics: Science and Systems Conference (RSS’13)<br>
          [<a href="http://www.roboticsproceedings.org/rss09/p26.pdf" id="pub">paper</a>] | <pub_note>acceptance rate: 30%</pub_note></p>

          <p>Bilge Mutlu, Allison Terrell, and Chien-Ming Huang<br>
          <span class="pub_hl">Coordination Mechanisms in Human-Robot Collaboration</span><br>
          <b>Workshop</b>: HRI Workshop on Collaborative Manipulation (HRI’13)<br>
          [<a href="http://pages.cs.wisc.edu/~bilge/pubs/2013/HRI13-W-Mutlu.pdf" id="pub">paper</a>] </p>

          <p>Chien-Ming Huang<br>
          <span class="pub_hl">Designing Effective Multimodal Behaviors for Robots: A Data-Driven Perspective</span><br>
          ACM on Interaction Conference on Multimodal Interaction (ICMI’13)<br>
          [<a href="https://dl.acm.org/authorize.cfm?key=N42661" id="pub">paper</a>] </p>
          
          <h3>2012</h3>
          <p>Chien-Ming Huang and Bilge Mutlu<br>
          <span class="pub_hl">Robot Behavior Toolkit: Generating Effective Social Behaviors for Robots</span><br>
          <b>Conference</b>: ACM/IEEE International Conference on Human-Robot Interaction (HRI’12)<br>
          [<a href="publications/2012-hri-huang.pdf" id="pub">paper</a>] | <pub_note>acceptance rate: 25%</pub_note></p>

          <p>Chien-Ming Huang<br>
          <span class="pub_hl">Generating Effective Social Behaviors for Robots</span><br>
          HRI Pioneers Workshop<br>
          <pub_note>acceptance rate: 28%</pub_note></p>

          <p>Chien-Ming Huang<br>
          <span class="pub_hl">Designing Effective Behaviors for Educational Embodied Agents</span><br>
          ACM/SIGCHI Conference on Human Factors in Computing Systems (CHI’12)<br>
          [<a href="https://dl.acm.org/authorize.cfm?key=N71252" id="pub">paper</a>] | <pub_note>acceptance rate: 23%</pub_note></p>

          <h3>Prior to 2012</h3>
          <p>Chien-Ming Huang and Andrea L. Thomaz<br>
          <span class="pub_hl">Effects of Responding to, Initiating and Ensuring Joint Attention in Human-Robot Interaction</span><br>
          <b>Conference</b>: IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN’11)<br>
          [<a href="https://ieeexplore.ieee.org/abstract/document/6005230" id="pub">paper</a>] </p>

          <p>Chien-Mign Huang<br>
          <span class="pub_hl">Joint Attention in Human-Robot Interaction</span><br>
      	  Master of Science (M.S.) Thesis. College of Computing, Georgia Institute of Technology</p>

          <p>Chien-Ming Huang and Andrea L. Thomaz<br>
          <span class="pub_hl">Joint Attention in Human-Robot Interaction</span><br>
          AAAI Fall Symposium on Dialog with Robots<br>
          [<a href="http://www.aaai.org/ocs/index.php/FSS/FSS10/paper/download/2173/2771" id="pub">paper</a>] </p>

          <hr />
          
        </div>
      </section>
    </article>

    <!-- Footer -->
    <footer id="footer">
      <ul class="icons">
        <li><a href="https://twitter.com/chienming_huang" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
        <li><a href="mailto:cmhuang@cs.jhu.edu" class="icon fa-envelope-o"><span class="label">Email</span></a></li>
      </ul>
      <ul class="copyright">
        <li>&copy; Intuitive Computing Laboratory</li>
        <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
      </ul>
    </footer>

  </div>

  <!-- Scripts -->
  <script src="assets/js/jquery.min.js"></script>
  <script src="assets/js/jquery.scrollex.min.js"></script>
  <script src="assets/js/jquery.scrolly.min.js"></script>
  <script src="assets/js/browser.min.js"></script>
  <script src="assets/js/breakpoints.min.js"></script>
  <script src="assets/js/util.js"></script>
  <script src="assets/js/main.js"></script>

</body>

</html>
